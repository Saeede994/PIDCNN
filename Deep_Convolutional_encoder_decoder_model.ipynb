{"cells":[{"cell_type":"code","execution_count":null,"id":"1a4e1474","metadata":{"id":"1a4e1474"},"outputs":[],"source":["#import required packages\n","\n","import math\n","import torch\n","import torch.nn as nn\n","import cv2\n","import numpy as np\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.optim.lr_scheduler import StepLR\n","import json\n","from time import time\n","import argparse\n","import sys\n","sys.argv=['']\n","import os\n","import h5py\n","from torch.utils.data import DataLoader, TensorDataset,random_split\n","import glob\n","import natsort\n","from PIL import Image\n","#import matplotlib.pyplot as plt\n","import time\n","import numpy as np\n","import torchvision.transforms as T\n","from torchvision import datasets\n","from torchvision.utils import make_grid\n","from torchvision.utils import save_image\n","import random\n","import PIL.ImageOps\n","import pandas as pd\n","import os\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n","import matplotlib.pyplot as plt\n","from torch.nn.modules.utils import _quadruple\n","from sklearn.model_selection import KFold\n","from scipy.ndimage import gaussian_filter"]},{"cell_type":"code","execution_count":null,"id":"c5abd725","metadata":{"id":"c5abd725"},"outputs":[],"source":["# Set the seed for reproducibility\n","seed = 42\n","torch.manual_seed(seed)\n","random.seed(seed)\n","np.random.seed(seed)\n","g_cpu = torch.Generator().manual_seed(seed)\n","g_cuda = torch.Generator(device='cuda').manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","# Ensure deterministic behavior for CUDA operations\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\""]},{"cell_type":"markdown","id":"ec635ecb","metadata":{"id":"ec635ecb"},"source":["## Loading and preprocessing Dataset"]},{"cell_type":"code","execution_count":null,"id":"3af73e8f","metadata":{"id":"3af73e8f"},"outputs":[],"source":["# import required libraries\n","\n","\n","class LoadDataset:\n","    def __init__(self, dataset_path,transform_layout,in_channels,out_channels,n_images,inputdata_type,outputdata_type):\n","        '''\n","        This class reads the dataset from specified folder.\n","        '''\n","        self.dataset_path=dataset_path\n","        self.transform_layout=transform_layout\n","        self.in_channels=in_channels\n","        self.out_channels=out_channels\n","        self.n_images=n_images\n","        self.inputdata_type=inputdata_type\n","        self.outputdata_type=outputdata_type\n","\n","\n","\n","        self.U_input, self.V_input = [], []\n","        self.U_output, self.V_output = [], []\n","\n","        self.read_dataset()\n","    def read_dataset(self):\n","        '''\n","        This function reads the dataset from the specified folder.\n","        '''\n","        # Read the dataset from the specified folder\n","        if self.in_channels==2:\n","            if self.inputdata_type=='Larsen':\n","                self.U_input=natsort.natsorted(glob.glob(os.path.join(self.dataset_path, '*u_flow.npy')))\n","                self.V_input=natsort.natsorted(glob.glob(os.path.join(self.dataset_path, '*v_flow.npy')))\n","            else:\n","                print('The dataset type is not supported')\n","        else:\n","            print('The number of input channels is not supported')\n","\n","        if self.out_channels==2:\n","            if  self.outputdata_type=='CFD':\n","                self.U_output= natsort.natsorted(glob.glob(os.path.join(self.dataset_path, '*_sw.npy')))\n","                self.V_output= natsort.natsorted(glob.glob(os.path.join(self.dataset_path, '*_cw.npy')))\n","                self.P= natsort.natsorted(glob.glob(os.path.join(self.dataset_path, '*_p.npy')))\n","                self.K= natsort.natsorted(glob.glob(os.path.join(self.dataset_path, '*_k.npy')))\n","                self.Omega= natsort.natsorted(glob.glob(os.path.join(self.dataset_path, '*_omega.npy')))\n","                self.Coordin= natsort.natsorted(glob.glob(os.path.join(self.dataset_path, '*_layout_pixels.npy')))\n","            else:\n","                print('The dataset type is not supported')\n","\n","        return\n","\n","\n","\n","    def __getitem__(self, index):\n","        '''\n","        This function returns the data at the specified index.\n","        '''\n","        if self.n_images:\n","            if index >= self.n_images:\n","                raise Exception('CustomDataSet:Error: Index out of bounds inside __get_item__')\n","\n","        if self.in_channels==2:\n","            input_U = np.load(self.U_input[index])\n","#             input_U=self.gaussian_smooth(input_U)\n","            input_U=torch.from_numpy(input_U.copy()).unsqueeze(0)\n","\n","            input_V = np.load(self.V_input[index])\n","#             input_V=self.gaussian_smooth(input_V)\n","            input_V=torch.from_numpy(input_V.copy()).unsqueeze(0)\n","\n","            input_data=torch.cat((input_U,input_V))\n","        if self.out_channels==2:\n","            output_U = np.load(self.U_output[index])\n","            output_U=np.rot90(output_U, axes=(1, 0))\n","\n","            ############################################################################################################\n","            P = np.load(self.P[index])\n","            P=np.rot90(P, axes=(1, 0))\n","            P=torch.from_numpy(P.copy()).unsqueeze(0)\n","            P=F.interpolate(P.unsqueeze(0) , size=(400), mode='bilinear', align_corners=True).squeeze(0)\n","            ############################################################################################################\n","            K = np.load(self.K[index])\n","            K=np.rot90(K, axes=(1, 0))\n","            K=torch.from_numpy(K.copy()).unsqueeze(0)\n","            K=F.interpolate(K.unsqueeze(0) , size=(400), mode='bilinear', align_corners=True).squeeze(0)\n","            ############################################################################################################\n","            Omega = np.load(self.Omega[index])\n","            Omega=np.rot90(Omega, axes=(1, 0))\n","            Omega=torch.from_numpy(Omega.copy()).unsqueeze(0)\n","            Omega=F.interpolate(Omega.unsqueeze(0) , size=(400), mode='bilinear', align_corners=True).squeeze(0)\n","            ############################################################################################################\n","            output_V = np.load(self.V_output[index])\n","            output_V=np.rot90(output_V, axes=(1, 0))\n","\n","            #################################################################################\n","            force=np.zeros((400,400))\n","            loc_layout=self.Coordin[index]\n","            lay=np.load(loc_layout)\n","            cp=0.5926\n","            ct=0.889\n","            a=1-(cp/ct)\n","            for i in range(lay.shape[0]):\n","\n","\n","                U=np.sqrt(output_U[int(lay[i][1]),int(lay[i][0])-5]**2+output_V[int(lay[i][1]),int(lay[i][0])-5]**2)\n","\n","                Force=(2*U**2*a*(1-a))/4\n","\n","                force[int(lay[i][1])-4:int(lay[i][1])+4,int(lay[i][0])]=Force\n","            force_tensor=torch.from_numpy(force.copy())\n","            force_tensor=force_tensor.unsqueeze(0)\n","\n","            output_V=torch.from_numpy(output_V.copy()).unsqueeze(0)\n","            output_V=F.interpolate(output_V.unsqueeze(0), size=(400), mode='bilinear', align_corners=True).squeeze(0)\n","            output_U=torch.from_numpy(output_U.copy()).unsqueeze(0)\n","            output_U=F.interpolate(output_U.unsqueeze(0) , size=(400), mode='bilinear', align_corners=True).squeeze(0)\n","\n","            output_data=torch.cat((output_U,output_V))\n","\n","\n","        return input_data,output_data,P,K,Omega,force_tensor\n","\n","\n","\n","    def __len__(self):\n","        '''\n","        This function returns the length of the dataset.\n","        '''\n","        return self.n_images\n","\n","\n","class Preprocessor:\n","    def __init__(self, method='minmax'):\n","        self.method = method\n","        self.global_min_U_input = None\n","        self.global_max_U_input = None\n","        self.global_min_V_input = None\n","        self.global_max_V_input = None\n","        self.global_mean_U_input = None\n","        self.global_std_U_input = None\n","        self.global_mean_V_input = None\n","        self.global_std_V_input = None\n","        self.global_min_U_output = None\n","        self.global_max_U_output = None\n","        self.global_min_V_output = None\n","        self.global_max_V_output = None\n","        self.global_mean_U_output = None\n","        self.global_std_U_output = None\n","        self.global_mean_V_output = None\n","        self.global_std_V_output = None\n","\n","    def fit(self, dataset):\n","        '''\n","        This function calculates the global min and max values (or mean and std) for input_U and input_V.\n","        '''\n","        all_U_input = []\n","        all_V_input = []\n","        all_U_output = []\n","        all_V_output = []\n","\n","        for i in range(len(dataset)):\n","            input_data, output_data,P,K,Omega,force_tensor = dataset[i]\n","            input_U = input_data[0].numpy()\n","            input_V = input_data[1].numpy()\n","            output_U = output_data[0].numpy()\n","            output_V = output_data[1].numpy()\n","            all_U_input.append(input_U)\n","            all_V_input.append(input_V)\n","            all_U_output.append(output_U)\n","            all_V_output.append(output_V)\n","\n","        all_U_input = np.concatenate(all_U_input)\n","        all_V_input = np.concatenate(all_V_input)\n","        all_U_output = np.concatenate(all_U_output)\n","        all_V_output = np.concatenate(all_V_output)\n","\n","        if self.method == 'minmax':\n","            self.global_min_U_input = all_U_input.min()\n","            self.global_max_U_input = all_U_input.max()\n","            self.global_min_V_input = all_V_input.min()\n","            self.global_max_V_input = all_V_input.max()\n","            self.global_min_U_output = all_U_output.min()\n","            self.global_max_U_output = all_U_output.max()\n","            self.global_min_V_output = all_V_output.min()\n","            self.global_max_V_output = all_V_output.max()\n","\n","        elif self.method == 'standardization':\n","            self.global_mean_U_input = all_U_input.mean()\n","            self.global_std_U_input = all_U_input.std()\n","            self.global_mean_V_input = all_V_input.mean()\n","            self.global_std_V_input = all_V_input.std()\n","            self.global_mean_U_output = all_U_output.mean()\n","            self.global_std_U_output = all_U_output.std()\n","            self.global_mean_V_output = all_V_output.mean()\n","            self.global_std_V_output = all_V_output.std()\n","\n","\n","\n","\n","    def transform(self, input_data, output_data):\n","        '''\n","        This function applies the specified normalization method on the data.\n","        '''\n","        if self.method == 'minmax' and (self.global_min_U_input is None or self.global_max_U_input is None):\n","            raise ValueError(\"Min and max values for minmax scaling are not set. Please call the fit method first.\")\n","        elif self.method == 'standardization' and (self.global_mean_U_input is None or self.global_std_U_input is None):\n","            raise ValueError(\"Mean and std values for standardization are not set. Please call the fit method first.\")\n","\n","        input_U, input_V = input_data[0].numpy(), input_data[1].numpy()\n","        output_U, output_V = output_data[0].numpy(), output_data[1].numpy()\n","\n","        if self.method == 'standardization':\n","            input_U = (input_U - self.global_mean_U_input) / self.global_std_U_input\n","            input_V = (input_V - self.global_mean_V_input) / self.global_std_V_input\n","            output_U = (output_U - self.global_mean_U_output) / self.global_std_U_output\n","            output_V = (output_V - self.global_mean_V_output) / self.global_std_V_output\n","        elif self.method == 'minmax':\n","\n","            input_U = (input_U - self.global_min_U_input) / (self.global_max_U_input - self.global_min_U_input)\n","\n","            input_V = -1 + 2 * (input_V - self.global_min_V_input) / (self.global_max_V_input - self.global_min_V_input)\n","\n","\n","\n","\n","        input_data = torch.from_numpy(np.stack((input_U, input_V)))\n","        output_data = torch.from_numpy(np.stack((output_U, output_V)))\n","\n","        return input_data, output_data\n","\n","    def fit_transform(self, dataset):\n","        '''\n","        This function first fits the preprocessor on the dataset and then transforms it.\n","        '''\n","        self.fit(dataset)\n","        transformed_dataset = []\n","\n","        for i in range(len(dataset)):\n","            input_data, output_data,P,K,Omega,force_tensor = dataset[i]\n","            input_data, output_data = self.transform(input_data, output_data)\n","            transformed_dataset.append((input_data, output_data,P,K,Omega,force_tensor ))\n","\n","        return transformed_dataset\n","\n","    def transform_only(self, dataset):\n","        '''\n","        This function transforms the dataset without fitting, using already fitted values.\n","        '''\n","        transformed_dataset = []\n","\n","        for i in range(len(dataset)):\n","            input_data, output_data,P,K,Omega,force_tensor = dataset[i]\n","            input_data, output_data = self.transform(input_data, output_data)\n","            transformed_dataset.append((input_data, output_data,P,K,Omega,force_tensor))\n","\n","        return transformed_dataset\n","\n","    def get_max_min(self,dataset):\n","        return self.global_max_U_output,self.global_min_U_output,self.global_max_V_output,self.global_min_V_output\n","\n","\n","\n","import torchvision.transforms as T\n","import matplotlib.pyplot as plt\n","import numpy as np\n","transforms_list = [\n","                   T.Grayscale(),\n","\n","                   T.ToTensor()]\n","transform_layout = T.Compose(transforms_list)\n","dataset_path=r'.\\data\\New_train_1'\n","\n","in_channels=2\n","out_channels=2\n","n_images=190\n","inputdata_type='Larsen'\n","outputdata_type='CFD'\n","dataset=LoadDataset(dataset_path,transform_layout,in_channels,out_channels,n_images,inputdata_type,outputdata_type)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"2701bb0d","metadata":{"id":"2701bb0d"},"outputs":[],"source":["preprocessor = Preprocessor(method='minmax')\n","preprocessor.fit(dataset)\n","U_max,U_min,V_max,V_min=preprocessor.get_max_min(dataset)\n","transformed_dataset = preprocessor.fit_transform(dataset)\n","train_data=transformed_dataset\n"]},{"cell_type":"code","execution_count":null,"id":"cc733f20","metadata":{"id":"cc733f20"},"outputs":[],"source":["dataset_path=r'.\\data\\valid1'\n","in_channels=2\n","out_channels=2\n","n_images=8\n","inputdata_type='Larsen'\n","outputdata_type='CFD'\n","dataset_valid=LoadDataset(dataset_path,transform_layout,in_channels,out_channels,n_images,inputdata_type,outputdata_type)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4a7679f1","metadata":{"id":"4a7679f1"},"outputs":[],"source":["\n","transformed_dataset_valid = preprocessor.transform_only(dataset_valid)\n","valid_data=transformed_dataset_valid"]},{"cell_type":"markdown","source":["## Dataset Visualizzation"],"metadata":{"id":"EmdDK4SNMcgp"},"id":"EmdDK4SNMcgp"},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fig = plt.figure(figsize=(10, 10))\n","for i in range(3):\n","    # Plot input\n","    ax = fig.add_subplot(3, 3, i + 1)\n","    img = ax.imshow(train_data.__getitem__(i)[1][0, :, :].squeeze(0), cmap='jet')\n","    ax.set_title('Inputs_{}'.format(i + 1))\n","    ax.axis(\"off\")\n","    fig.colorbar(img, ax=ax, fraction=0.046, pad=0.04)\n","\n","    # Plot Target_U\n","    ax = fig.add_subplot(3, 3, i + 1 + 3)\n","    img = ax.imshow(train_data.__getitem__(i)[1][1, :, :], cmap='jet')\n","    ax.set_title('Target_U{}'.format(i + 1))\n","    ax.axis(\"off\")\n","    fig.colorbar(img, ax=ax, fraction=0.046, pad=0.04)\n","\n","    # Plot Target_V\n","    ax = fig.add_subplot(3, 3, i + 1 + 6)\n","    img = ax.imshow(train_data.__getitem__(i)[2][0, :, :], cmap='jet')\n","    ax.set_title('Target_V{}'.format(i + 1))\n","    ax.axis(\"off\")\n","    fig.colorbar(img, ax=ax, fraction=0.046, pad=0.04)\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"DaKhPeULUoE8"},"id":"DaKhPeULUoE8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","nvalid=len(valid_data)\n","\n","ntrain=len(train_data)\n","print('Number of train data:{}'.format(ntrain ))\n","print('Number of valid data:{}'.format(nvalid ))"],"metadata":{"id":"pMz29oE8Ur7Q"},"id":"pMz29oE8Ur7Q","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"517755fc","metadata":{"id":"517755fc"},"source":["## Evaluation Function"]},{"cell_type":"code","execution_count":null,"id":"9378f9db","metadata":{"id":"9378f9db"},"outputs":[],"source":["# Evaluating the validation and test set\n","def evaluate(model,epoch,valid_set):\n","\n","\n","\n","    val_loss=0\n","\n","\n","    device='cuda'\n","\n","\n","\n","\n","    for step,(inputs,target,P,K,Omega,force) in enumerate(valid_set):\n","\n","\n","        model.eval()\n","\n","            #############################################\n","        inputs  = inputs.to(device, dtype=torch.float)\n","\n","        targets= target.to(device, dtype=torch.float)\n","\n","\n","\n","        outputs = model(inputs)\n","        loss_MSE=F.mse_loss(outputs, targets, reduction='sum')\n","\n","\n","        valid_loss_log=torch.log(1+loss_MSE)\n","#\n","\n","\n","\n","        validation_loss=loss_MSE.item()\n","        validation_loss_log=valid_loss_log.item()\n","\n","\n","\n","\n","\n","\n","    return validation_loss,validation_loss_log"]},{"cell_type":"markdown","source":["## Visualzation function"],"metadata":{"id":"aYcXlc33M1LB"},"id":"aYcXlc33M1LB"},{"cell_type":"code","execution_count":null,"id":"5b323703","metadata":{"id":"5b323703"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def visual( img_target,img_pred, gpu=0, flag_torch=0, sv=False):\n","    if gpu:\n","\n","        img_target = img_target.cpu().detach()\n","\n","        img_pred = img_pred.cpu().detach()\n","\n","\n","\n","    if flag_torch:\n","#         mass_target = mass_target.numpy()\n","        img_target = img_target.numpy()\n","\n","        img_pred = img_pred.numpy()\n","\n","\n","    if flag_torch == 2:\n","        img_target = np.transpose(img_target[:, :, :, :, :], [0, 4, 2, 3, 1]).squeeze()\n","        img_pred = np.transpose(img_pred[:, :, :, :, :], [0, 4, 2, 3, 1]).squeeze()\n","\n","\n","#     mass_out = np.transpose(mass_out[:5, :, :, :], [0, 2, 3, 1])\n","    img_target = np.transpose(img_target[:5, :, :, :], [0, 2, 3, 1])\n","    img_pred = np.transpose(img_pred[:5, :, :, :], [0, 2, 3, 1])\n","\n","\n","    fig = plt.figure(figsize=(10, 10))\n","    for i in range(3):\n","\n","\n","        ax = fig.add_subplot(6, 3, i + 1)\n","        im = ax.imshow(abs(img_target[:,:,:,0][i]-img_pred[:,:,:,0][i]), cmap='jet',vmin=0,vmax=0.1)\n","        ax.set_title('Error_U{}'.format(i+1))\n","        ax.axis(\"off\")\n","        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","\n","        ax = fig.add_subplot(6, 3, i +3+ 1)\n","        im = ax.imshow(abs(img_target[:,:,:,1][i]-img_pred[:,:,:,1][i]), cmap='jet',vmin=0,vmax=0.1)\n","        ax.set_title('Error_V{}'.format(i+1))\n","        ax.axis(\"off\")\n","        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","\n","\n","\n","        ax = fig.add_subplot(6, 3, i + 1 + 6)\n","        im = (img_target[:,:,:,0][i])\n","        im = ax.imshow(im, cmap='jet')\n","        ax.set_title('Target_U{}'.format(i+1))\n","        ax.axis(\"off\")\n","        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","\n","        ax = fig.add_subplot(6, 3, i + 1 + 9)\n","        im = (img_pred[:,:,:,0][i])\n","        im = ax.imshow(im, cmap='jet')\n","        ax.set_title('Prediction_U{}'.format(i+1))\n","        ax.axis(\"off\")\n","        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","\n","        ax = fig.add_subplot(6, 3, i + 1 + 12)\n","        im = (img_target[:,:,:,1][i])\n","        im = ax.imshow(im, cmap='jet')\n","        ax.set_title('Target_V{}'.format(i+1))\n","        ax.axis(\"off\")\n","        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","\n","        ax = fig.add_subplot(6, 3, i + 1 + 15)\n","        im = (img_pred[:,:,:,1][i])\n","        im = ax.imshow(im, cmap='jet')\n","        ax.set_title('Prediction_V{}'.format(i+1))\n","        ax.axis(\"off\")\n","        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","\n","    plt.tight_layout()\n","    plt.show()\n","#     if sv:\n","#         fig.savefig('temp.png')\n","\n","# Example usage\n","# visual(img_layout, img_target, img_pred, gpu=1, flag_torch=1, sv=True)\n"]},{"cell_type":"markdown","id":"78b373f2","metadata":{"id":"78b373f2"},"source":["## Network"]},{"cell_type":"code","execution_count":null,"id":"c97d1aae","metadata":{"id":"c97d1aae"},"outputs":[],"source":["\n","#Convolutional layers in the dense blocks\n","\n","class conv_layer(nn.Module):\n","    def __init__(self,init_features,kernel_conv,stride_conv,padding_conv,growth_rate,bn_size,drop_out,bottleneck):\n","        super(). __init__()\n","        if bottleneck and init_features>growth_rate*bn_size:\n","            self.conv=nn.Sequential(\n","                nn.BatchNorm2d(init_features),\n","                nn.ReLU(inplace='True'),\n","                nn.Conv2d(init_features,growth_rate*bn_size,kernel_size=1,stride=1,padding=0,bias=False),\n","                nn.BatchNorm2d(growth_rate*bn_size),\n","                nn.ReLU(inplace='True'),\n","                nn.Conv2d(growth_rate*bn_size,growth_rate,kernel_conv,stride_conv,padding_conv,bias=False)\n","            )\n","        else:\n","            self.conv=nn.Sequential(\n","                nn.BatchNorm2d(init_features),\n","                nn.ReLU(inplace='True'),\n","                nn.Conv2d(init_features,growth_rate,kernel_conv,stride_conv,padding_conv,bias=False)\n","            )\n","        self.drop_out=drop_out\n","\n","    def forward(self,x):\n","        out=self.conv(x)\n","        if self.drop_out>0:\n","            out = F.dropout(out, p=self.drop_out)\n","        return torch.cat([x,out],1)\n","\n","# Dense blocks\n","\n","class Dense_block(nn.Module):\n","    def __init__(self,init_features,kernel_conv,stride_conv,padding_conv,conv_layer,n_layers,growth_rate,bn_size,drop_out,bottleneck):\n","        super().__init__()\n","        self.layer = self._make_layer(init_features,kernel_conv,stride_conv,padding_conv,n_layers,conv_layer,growth_rate,bn_size,drop_out,bottleneck)\n","    def _make_layer(self,init_features,kernel_conv,stride_conv,padding_conv,n_layers,conv_layer,growth_rate,bn_size,drop_out,bottleneck):\n","        layers=[]\n","        for i in range(n_layers):\n","            layers.append(conv_layer(init_features+i*growth_rate,kernel_conv,stride_conv,padding_conv,growth_rate,bn_size,drop_out,bottleneck))\n","        return nn.Sequential(*layers)\n","    def forward(self, x):\n","        return self.layer(x)\n","#Encoders and decoders\n","\n","class Encode_Decode(nn.Module):\n","    def __init__(self,init_features,kernel,stride,padding,output_padding,out_features,growth_rate,drop_out,down,bottleneck):\n","        super().__init__()\n","        self.drop_out=drop_out\n","        if down:\n","            if bottleneck:\n","                self.block1=nn.Sequential(nn.BatchNorm2d(init_features),\n","                    nn.ReLU(inplace=True),\n","                    nn.Conv2d(init_features,out_features,kernel_size=1,stride=1,padding=0,bias=False),\n","                    nn.BatchNorm2d(out_features),\n","                    nn.ReLU(inplace=True),\n","                    nn.Conv2d(out_features,out_features,kernel,stride,padding,bias=False)\n","                    )\n","            else:\n","                self.block1=nn.Sequential(nn.BatchNorm2d(init_features),\n","                    nn.ReLU(inplace=True),\n","                    nn.Conv2d(init_features,out_features,kernel,stride,padding,bias=False)\n","                    )\n","        else:\n","            if bottleneck:\n","                self.block1=nn.Sequential(nn.BatchNorm2d(init_features),\n","                    nn.ReLU(inplace=True),\n","                    nn.Conv2d(init_features,out_features,kernel_size=1,stride=1,padding=0,bias=False),\n","                    nn.BatchNorm2d(out_features),\n","                    nn.ReLU(inplace=True),\n","                    nn.ConvTranspose2d(out_features,out_features,kernel,stride,padding,output_padding,bias=False)\n","                    )\n","\n","            else:\n","                self.block1=nn.Sequential(nn.BatchNorm2d(init_features),\n","                    nn.ReLU(inplace=True),\n","                    nn.ConvTranspose2d(out_features,out_features,kernel,stride,padding,output_padding,bias=False)\n","                                         )\n","    def forward(self,x):\n","        out=self.block1(x)\n","        if self.drop_out>0:\n","            out = F.dropout(out, p=self.drop_out)\n","        return out\n","\n","class last_decode(nn.Module):\n","    def __init__(self,init_features,out_channels,kernel_size,stride,padding,output_padding,drop_out):\n","        super().__init__()\n","        self.norm1=nn.BatchNorm2d(init_features)\n","        self.relu1=nn.ReLU(inplace=True)\n","        self.conv1=nn.Conv2d(init_features,init_features//2,kernel_size=1,stride=1,padding=0,bias=False)\n","        self.norm2=nn.BatchNorm2d(init_features//2)\n","        self.relu2=nn.ReLU(inplace=True)\n","        self.conv2=nn.ConvTranspose2d(init_features//2,out_channels,kernel_size,stride,padding,output_padding,bias=False)\n","        self.drop_out=drop_out\n","    def forward(self,x):\n","        out=self.conv1(self.relu1(self.norm1(x)))\n","        out=self.conv2(self.relu2(self.norm2(out)))\n","        if self.drop_out>0:\n","            out = F.dropout(out, p=self.drop_out)\n","        return out\n","\n"]},{"cell_type":"code","execution_count":null,"id":"6f96dd88","metadata":{"id":"6f96dd88"},"outputs":[],"source":["\n","class Dense_C8_one_layer_Added1(nn.Module):\n","    def __init__(self,in_channels,kernel,stride,padding,output_padding,out_channels_V,out_channels_P,init_features,growth_rate,bn_size,bottleneck,drop_out):\n","        super().__init__()\n","        block=conv_layer\n","        self.conv1=nn.Conv2d(in_channels,init_features,kernel[3], stride[3], padding[3],bias=False)\n","\n","        n_layers=2\n","        self.dense_block1=Dense_block(init_features,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features1=init_features+growth_rate*n_layers\n","        self.encode1=Encode_Decode(in_features1,kernel[1],stride[1],padding[1],output_padding[0],in_features1//2,growth_rate,drop_out,down=True,bottleneck=True)\n","\n","        n_layers=2\n","        self.dense_block2=Dense_block(in_features1//2,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features2=in_features1//2+growth_rate*n_layers\n","        self.encode2=Encode_Decode(in_features2,kernel[1],stride[1],padding[1],output_padding[0],in_features2//2,growth_rate,drop_out,down=True,bottleneck=True)\n","\n","        n_layers=2\n","        self.dense_block3=Dense_block(in_features2//2,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features3=in_features2//2+growth_rate*n_layers\n","        self.encode3=Encode_Decode(in_features3,kernel[1],stride[1],padding[1],output_padding[0],in_features3//2,growth_rate,drop_out,down=True,bottleneck=True)\n","        #####\n","        n_layers=2\n","        self.dense_block4=Dense_block(in_features3//2,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features4=in_features3//2+growth_rate*n_layers\n","        self.encode4=Encode_Decode(in_features4,kernel[1],stride[1],padding[1],output_padding[0],in_features4//2,growth_rate,drop_out,down=True,bottleneck=True)\n","        #####\n","        n_layers=4\n","        self.dense_block5=Dense_block(in_features4//2,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features11=in_features4//2+growth_rate*n_layers\n","        self.decode1=Encode_Decode(in_features11,kernel[1],stride[1],padding[1],output_padding[1],in_features11//2,growth_rate,drop_out,down=False,bottleneck=True)\n","\n","        n_layers=2\n","        in_features=in_features11//2+in_features3//2\n","        self.dense_block11=Dense_block(in_features,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features22=in_features+growth_rate*n_layers\n","        self.decode2=Encode_Decode(in_features22,kernel[1],stride[1],padding[1],output_padding[2],in_features22//2,growth_rate,drop_out,down=False,bottleneck=True)\n","\n","        n_layers=2\n","        in_features=in_features22//2+in_features2//2\n","        self.dense_block22=Dense_block(in_features,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features33=in_features+growth_rate*n_layers\n","        self.decode3=Encode_Decode(in_features33,kernel[1],stride[1],padding[1],output_padding[2],in_features33//2,growth_rate,drop_out,down=False,bottleneck=True)\n","\n","        #####\n","        n_layers=2\n","        in_features=in_features33//2+in_features1//2\n","        self.dense_block33=Dense_block(in_features,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features44=in_features+growth_rate*n_layers\n","        self.decode4=Encode_Decode(in_features44,kernel[1],stride[1],padding[1],output_padding[2],in_features44//2,growth_rate,drop_out,down=False,bottleneck=True)\n","        ####\n","\n","        n_layers=2\n","\n","        in_features=in_features44//2\n","        self.dense_block44=Dense_block(in_features,kernel[0],stride[0],padding[0],block,n_layers,growth_rate,bn_size,drop_out,bottleneck)\n","        in_features_last=in_features+growth_rate*n_layers\n","        self.last_V=last_decode(in_features_last,out_channels_V,kernel[2],stride[2],padding[2],output_padding[3],drop_out=0)\n","\n","\n","\n","\n","\n","\n","    def forward(self,x):\n","        out1=self.conv1(x)\n","\n","        out2=self.encode1(self.dense_block1(out1))\n","\n","        out3=self.encode2(self.dense_block2(out2))\n","\n","        out4=self.encode3(self.dense_block3(out3))\n","\n","        out5=self.encode4(self.dense_block4(out4))\n","\n","       #############################################################################################\n","        out11=self.decode1(self.dense_block5(out5))\n","        out11=torch.cat([out4, out11], 1)\n","        out11=self.dense_block11(out11)\n","        out22=self.decode2(out11)\n","        out22=torch.cat([out3, out22], 1)\n","        out33=self.decode3(self.dense_block22(out22))\n","        out33=torch.cat([out33, out2], 1)\n","        out44=self.decode4(self.dense_block33(out33))\n","        out_V=self.dense_block44(out44)\n","        out_V=self.last_V(out_V)\n","        #Try different activations\n","        #self.activation=nn.Tanh()\n","        #self.activation=nn.Sigmoid()\n","        #out=self.scaled_shifted_tanh(out)\n","        self.activation=nn.Identity()\n","        out_V=self.activation(out_V)\n","        ############################################################\n","\n","\n","\n","\n","\n","\n","        return out_V\n","\n",""]},{"cell_type":"code","execution_count":null,"id":"43d25398","metadata":{"id":"43d25398"},"outputs":[],"source":["# added layer\n","    from torchsummary import summary\n","\n","    parser=argparse.ArgumentParser(\"Convolutional Encoder-Decoder networks\")\n","    parser.add_argument('--in_channel', type=int, default=2,help='number of input channels')\n","    parser.add_argument('--out_channel_V',type=int, default=2, help='numebr of output channels')\n","    parser.add_argument('--out_channel_P',type=int, default=1, help='numebr of output channels')\n","    parser.add_argument('--growth_rate',type=int, default=8, help='equivalent with K=16')\n","    parser.add_argument('--init_features', type=int, default=4, help='number of channels after the first convolutional layer')\n","    parser.add_argument('--bn_size',type=int, default=8, help='battleneck size')\n","    parser.add_argument('--bottleneck',type=str, default=False, help='battleneck')\n","    parser.add_argument('--drop_rate', type=int, default=0, help='dropout probability')\n","    parser.add_argument('--kernel', type=int, default=[7,7,4,6],help='kernel size[k_conv,k,k_last,k_first]')\n","    parser.add_argument('--stride',type=int, default=[1,2,2,2], help='stride[s_conv,s,s_last,s_first]')\n","    parser.add_argument('--output_padding', type=int, default=[1,0,1,0],help='padding[encoder,med_layer,decoder,last]')\n","    parser.add_argument('--padding', type=int, default=[3,3,1,2],help='padding[p_conv,p,p_last.p_first]')\n","    args=parser.parse_args()\n","\n","\n","    device = 'cuda'\n","    ConvNet=model(args.in_channel,args.kernel,args.stride,args.padding,args.output_padding,args.out_channel_V,args.out_channel_P, args.init_features,args.growth_rate,args.bn_size,bottleneck=False,drop_out=0)\n","    ConvNet=ConvNet.to(device)\n","    input_size=400\n","    summary(ConvNet, (2, input_size, input_size))\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c4f665f3","metadata":{"id":"c4f665f3"},"outputs":[],"source":["import torch.nn.init as init\n","#model initialization\n","def init_weights(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","        init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n","        if m.bias is not None:\n","            nn.init.constant_(m.bias, 0)"]},{"cell_type":"markdown","id":"4bbdd3fb","metadata":{"id":"4bbdd3fb"},"source":["## Sobel Filter"]},{"cell_type":"code","execution_count":null,"id":"27ff6ba4","metadata":{"id":"27ff6ba4"},"outputs":[],"source":["class SobelFilter(object):\n","\n","    def __init__(self, imsize, correct=True, device='cuda'):\n","        # conv2d is cross-correlation, need to transpose the kernel here\n","        self.HSOBEL_WEIGHTS_3x3 = torch.FloatTensor(\n","            np.array([[-1, -2, -1],\n","                     [ 0, 0, 0],\n","                     [1, 2, 1]])/(8*400) ).unsqueeze(0).unsqueeze(0).to(device)\n","\n","        self.VSOBEL_WEIGHTS_3x3 = self.HSOBEL_WEIGHTS_3x3.transpose(-1, -2)\n","\n","        self.VSOBEL_WEIGHTS_5x5 = torch.FloatTensor(\n","                    np.array([[-5, -4, 0, 4, 5],\n","                                [-8, -10, 0, 10, 8],\n","                                [-10, -20, 0, 20, 10],\n","                                [-8, -10, 0, 10, 8],\n","                                [-5, -4, 0, 4, 5]]) / (240*400)).unsqueeze(0).unsqueeze(0).to(device)\n","        self.HSOBEL_WEIGHTS_5x5 = self.VSOBEL_WEIGHTS_5x5.transpose(-1, -2)\n","\n","        modifier = np.eye(imsize)\n","        modifier[0:2, 0] = np.array([4, -1])\n","        modifier[-2:, -1] = np.array([-1, 4])\n","        self.modifier = torch.FloatTensor(modifier).to(device)\n","        self.correct = correct\n","\n","\n","    def grad_h(self, image, filter_size=3):\n","        \"\"\"Get image gradient along horizontal direction, or x axis.\n","        Option to do replicate padding for image before convolution.\n","        Args:\n","            image (Tensor): (1, 1, H, W)\n","            replicate_pad (None, int, 4-tuple): if 4-tuple, (padLeft, padRight, padTop,\n","                padBottom)\n","        \"\"\"\n","        image_width = image.shape[-1]\n","\n","        if filter_size == 3:\n","            replicate_pad = 1\n","            kernel = self.VSOBEL_WEIGHTS_3x3\n","        elif filter_size == 5:\n","            replicate_pad = 2\n","            kernel = self.VSOBEL_WEIGHTS_5x5\n","\n","        image = F.pad(image, _quadruple(replicate_pad), mode='replicate')\n","        grad = F.conv2d(image, kernel, stride=1, padding=0, bias=None) * image_width\n","        # modify the boundary based on forward & backward finite difference (three points)\n","        # forward [-3, 4, -1], backward [3, -4, 1]\n","        if self.correct:\n","            return torch.matmul(grad, self.modifier)\n","        else:\n","            return grad\n","\n","    def grad_v(self, image, filter_size=3):\n","        image_height = image.shape[-2]\n","        if filter_size == 3:\n","            replicate_pad = 1\n","            kernel = self.HSOBEL_WEIGHTS_3x3\n","        elif filter_size == 5:\n","            replicate_pad = 2\n","            kernel = self.HSOBEL_WEIGHTS_5x5\n","        image = F.pad(image, _quadruple(replicate_pad), mode='replicate')\n","        grad = F.conv2d(image, kernel, stride=1, padding=0,\n","            bias=None) * image_height\n","        # modify the boundary based on forward & backward finite difference\n","        if self.correct:\n","            return torch.matmul(self.modifier.t(), grad)\n","        else:\n","            return grad"]},{"cell_type":"code","execution_count":null,"id":"5bca6823","metadata":{"id":"5bca6823"},"outputs":[],"source":["# continuity equation\n","def continuity(ux,vy):\n","\n","\n","    loss=ux+vy\n","    return loss"]},{"cell_type":"code","execution_count":null,"id":"c3fce4c0","metadata":{"id":"c3fce4c0"},"outputs":[],"source":["# calculate gradients\n","def gradients(tensor,sobel):\n","    ux=sobel.grad_h(tensor[:,0:1,:,:], filter_size=5)\n","    uy=sobel.grad_v(tensor[:,0:1,:,:], filter_size=5)\n","\n","\n","    vx=sobel.grad_h(tensor[:,1:2,:,:], filter_size=5)\n","    vy=sobel.grad_v(tensor[:,1:2,:,:], filter_size=5)\n","    return ux,uy,vx,vy\n",""]},{"cell_type":"code","execution_count":null,"id":"fa361c41","metadata":{"id":"fa361c41"},"outputs":[],"source":["# satisfying boundray conditions\n","def BCs(ux,uy,vx,vy,outputs,targets):\n","    inlet=F.mse_loss(outputs[:,0:1,:,0],targets[:,0:1,:,0] , reduction='sum')+F.mse_loss(outputs[:,1:2,:,0],targets[:,1:2,:,0] , reduction='sum')\n","    outlet=F.mse_loss(ux[:,:,:,-1], torch.zeros_like(ux[:,:,:,-1]), reduction='sum')+F.mse_loss(vx[:,:,:,-1], torch.zeros_like(vx[:,:,:,-1]), reduction='sum')\n","    top=F.mse_loss(uy[:,:,:,-1], torch.zeros_like(uy[:,:,:,-1]), reduction='sum')+F.mse_loss(vy[:,:,:,-1], torch.zeros_like(vy[:,:,:,-1]), reduction='sum')\n","    bottom=F.mse_loss(uy[:,:,:,-1], torch.zeros_like(uy[:,:,:,-1]), reduction='sum')+F.mse_loss(vy[:,:,:,-1], torch.zeros_like(vy[:,:,:,-1]), reduction='sum')\n","    BC_loss=inlet+outlet+top+bottom\n","    return BC_loss"]},{"cell_type":"code","execution_count":null,"id":"0ebf1416","metadata":{"id":"0ebf1416"},"outputs":[],"source":["# Navier Stokes equations\n","def Navier_Stokes(tensor,ux,uy,vx,vy,P,k,omega,force,sobel):\n","    nu=1.5*10**-5\n","    mu=1.837*10**-5\n","    rho=1.225\n","    nut=k/omega\n","\n","\n","\n","    uxx=sobel.grad_h(ux, filter_size=5)\n","    uyy=sobel.grad_v(uy, filter_size=5)\n","    vyy=sobel.grad_v(vy, filter_size=5)\n","    vxx=sobel.grad_h(vx, filter_size=5)\n","    px=sobel.grad_h(P, filter_size=5)\n","    py=sobel.grad_v(P, filter_size=5)\n","\n","    termA=tensor[:,0:1,:,:]*ux+tensor[:,1:2,:,:]*uy\n","    termB=(-1/rho)*px\n","    termC=nu*(uxx+uyy)\n","    termD=nut*(2*ux)-(2/3)*k\n","\n","    termE=nut*(uy+vx)\n","    termDx=sobel.grad_h(termD)\n","    termEy=sobel.grad_v(termE)\n","\n","    NSx=termB+termC+termDx+termEy-termA-force\n","\n","\n","    termAA=tensor[:,0:1,:,:]*vx+tensor[:,1:2,:,:]*vy\n","    termBB=(-1/rho)*py\n","    termCC=nu*(vxx+vyy)\n","    termDD=nut*(vx+uy)\n","    termEE=nut*(2*vy)-(2/3)*k\n","    termDDx=sobel.grad_h(termDD)\n","    termEEy=sobel.grad_v(termEE)\n","    NSy=termBB+termCC+termDDx+termEEy-termAA\n","#     loss_Nsx=(NSx**2).sum()\n","#     loss_Nsy=(NSy**2).sum()\n","    loss_Nsx=NSx\n","    loss_Nsy=NSy\n","    return loss_Nsx,loss_Nsy"]},{"cell_type":"markdown","id":"b5644bf2","metadata":{"id":"b5644bf2"},"source":["## Training a physics-informed convolutional enocoder decoder"]},{"cell_type":"code","execution_count":null,"id":"5d9aa2e9","metadata":{"id":"5d9aa2e9"},"outputs":[],"source":["# Train Function\n","\n","def train(args,model,i,w_mse,w_mass,w_NSx,w_NSy,STEP):\n","\n","    device='cuda'\n","\n","    train_set=torch.utils.data.DataLoader(train_data, args.batch_size, pin_memory=True, num_workers=0)\n","    valid_set=torch.utils.data.DataLoader(valid_data, args.test_batch_size, pin_memory=True, num_workers=0)\n","\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate,\n","                       weight_decay=args.weight_decay)\n","\n","\n","#     scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=0,last_epoch=-1)\n","#     scheduler=ReduceLROnPlateau(optimizer,mode='min',threshold_mode='rel', cooldown=0, min_lr=0.00001, eps=1e-8,patience=15,factor=0.5)\n","\n","    scheduler = StepLR(optimizer, step_size=STEP, gamma=0.5)\n","\n","    n_out_pixels_train = args.ntrain * train_data[0][1].numel()\n","    n_out_pixels_valid= args.nvalid * valid_data[0][1].numel()\n","\n","\n","    train_losses=[]\n","    train_losses_MSE=[]\n","    train_losses_Mass=[]\n","    valid_losses=[]\n","    valid_losses_log=[]\n","    valid_losses_mass=[]\n","    RMSE_valid=[]\n","    RMSE_train=[]\n","    learning_rates=[]\n","\n","\n","    Epochs=[]\n","    best_loss=1e9\n","\n","    folder_path = r'./Minmax_input_No_output_gradual_BCs_NS_SSE/{}_{}_{}/{}'.format(w_mass,w_NSx,w_NSy,i)\n","\n","# Create the folder\n","    if not os.path.exists(folder_path):\n","        os.makedirs(folder_path)\n","\n","\n","    for epoch in range(args.epochs):\n","        # Train the Model\n","\n","        model.train()  # Change model to 'train' mod\n","\n","        train_loss=0\n","        train_loss_mse=0\n","        train_loss_mass=0\n","        train_loss_mse_log=0\n","        train_loss_BCs=0\n","        train_loss_Nsx=0\n","        train_loss_Nsy=0\n","\n","        for step,(inputs,targets,P,K,Omega,force_tensor) in enumerate(train_set):\n","\n","            inputs  = inputs.to(device, dtype=torch.float)\n","            targets= targets.to(device, dtype=torch.float)\n","            P= P.to(device, dtype=torch.float)\n","            K= K.to(device, dtype=torch.float)\n","            Omega= Omega.to(device, dtype=torch.float)\n","            force_tensor= force_tensor.to(device, dtype=torch.float)\n","\n","            model.zero_grad()\n","            outputs=model(inputs)\n","            outputs= outputs.to(device, dtype=torch.float)\n","\n","##################################################################################################\n","            Ux,Uy,Vx,Vy=gradients(outputs,SobelFilter(targets.shape[-1], correct=True))\n","            Ux_t,Uy_t,Vx_t,Vy_t=gradients(targets,SobelFilter(targets.shape[-1], correct=True))\n","            Boundray=BCs(Ux,Uy,Vx,Vy,outputs,targets)\n","\n","            mass_o=continuity(Ux,Vy)\n","            mass_t=continuity(Ux_t,Vy_t)\n","            mass=F.mse_loss(mass_o,mass_t , reduction='sum')\n","\n","\n","            loss_nx_o,loss_ny_o=Navier_Stokes(outputs,Ux,Uy,Vx,Vy,P,K,Omega,force_tensor,SobelFilter(targets.shape[-1], correct=True))\n","            loss_nx_t,loss_ny_t=Navier_Stokes(outputs,Ux_t,Uy_t,Vx_t,Vy_t,P,K,Omega,force_tensor,SobelFilter(targets.shape[-1], correct=True))\n","            loss_nx=F.mse_loss(loss_nx_o,loss_nx_t , reduction='sum')\n","            loss_ny=F.mse_loss(loss_ny_o,loss_ny_t , reduction='sum')\n","\n","            loss_Mass=torch.log(1+mass)\n","            loss_BCs=torch.log(1+Boundray)\n","            loss_NX=torch.log(1+loss_nx)\n","            loss_NY=torch.log(1+loss_ny)\n","            train_loss_mass+=loss_Mass.item()\n","            train_loss_BCs+=loss_BCs.item()\n","            train_loss_Nsx+=loss_NX.item()\n","            train_loss_Nsy+=loss_NY.item()\n","\n","#####################################################################################################\n","\n","\n","\n","\n","            loss_MSE=F.mse_loss(outputs,targets , reduction='sum')\n","\n","\n","            loss_MSE_log=torch.log(1+loss_MSE)\n","\n","#             loss_MSE_log=loss_MSE\n","            w0=(w_mass/args.epochs)*epoch\n","#             w0=w_mass\n","            w00=(w_NSx/args.epochs)*epoch\n","            w000=(w_NSy/args.epochs)*epoch\n","\n","\n","\n","            loss=w_mse*loss_MSE_log+w0*loss_Mass+w0*loss_BCs+w00*loss_NX+w000*loss_NY\n","\n","\n","\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n","\n","            optimizer.step()\n","\n","\n","\n","\n","            train_loss+=loss.item()\n","#\n","            train_loss_mse_log+=loss_MSE_log.item()\n","            train_loss_mse+=loss_MSE.item()\n","\n","\n","        train_losses.append(train_loss)\n","        train_losses_MSE.append(train_loss_mse)\n","        train_losses_Mass.append(train_loss_mass)\n","\n","\n","        rmse = np.sqrt(train_loss_mse / n_out_pixels_train)\n","\n","        RMSE_train.append(rmse)\n","\n","\n","        lr_rate=optimizer.param_groups[0]['lr']\n","\n","        learning_rates.append(lr_rate)\n","#         writer.add_scalar(\"loss/lr_rate\", lr_rate, epoch)\n","\n","        Epochs.append(epoch+1)\n","        model.eval()\n","        validation_loss,validation_loss_log=evaluate(model,epoch,valid_set)\n","#         writer.add_scalar(\"loss/validation_loss\", validation_loss_log, epoch)\n","        rmse_val = np.sqrt(validation_loss / n_out_pixels_valid)\n","\n","\n","\n","        valid_losses.append(validation_loss)\n","        valid_losses_log.append(validation_loss_log)\n","        RMSE_valid.append(rmse_val)\n","        scheduler.step()\n","\n","\n","\n","\n","        if epoch>=200:\n","            if validation_loss < best_loss:\n","                best_loss = validation_loss\n","\n","\n","\n","                torch.save(model.state_dict(), folder_path+'/model_data_{}_lr_{}_epoch_{}_batch_{}_step_{}_{}.pt'.format(ntrain,args.learning_rate,args.epochs,args.batch_size,STEP,i))\n","#\n","\n","\n","\n","\n","\n","\n","\n","        if epoch % 10 == 0:\n","            print((\"Epoch {}: , Train RMSE : {},Validation RMSE : {}\").format(\n","                      epoch ,rmse,rmse_val))\n","\n","            print((\"Epoch {}: ,Train Loss:{}, Train Mass: {}, Train MSE: {}, Valid MSE:{}\").format(\n","                       epoch ,train_loss,train_loss_mass,train_loss_mse_log,validation_loss))\n","\n","\n","        if epoch < (args.epochs-50):\n","            if args.plot:\n","                visual(targets, outputs, args.gpu, 1)\n","\n","\n","\n","\n","\n","\n","\n","\n","    if args.plot_LC:\n","\n","        plt.title(\"Training Curve\")\n","        plt.plot(Epochs, train_losses_MSE, label=\"Train\")\n","\n","        plt.plot(Epochs, valid_losses, label=\"Valid\")\n","\n","\n","        plt.legend(loc='best')\n","        plt.xlabel(\"Iterations\")\n","        plt.ylabel(\"Loss\")\n","        plt.show()\n","        plt.title(\"RMSE\")\n","        plt.plot(Epochs, RMSE_train, label=\"Train\")\n","\n","        plt.plot(Epochs, RMSE_valid, label=\"Valid\")\n","\n","\n","\n","\n","        plt.legend(loc='best')\n","        plt.xlabel(\"Iterations\")\n","        plt.ylabel(\"RMSE\")\n","        plt.show()\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"id":"53ec19f2","metadata":{"id":"53ec19f2"},"outputs":[],"source":["class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","args = AttrDict()"]},{"cell_type":"markdown","source":["## Train and Save Model"],"metadata":{"id":"BKT7Vi_cUgjQ"},"id":"BKT7Vi_cUgjQ"},{"cell_type":"code","source":["\n","args_dict = {\"gpu\": True,\n","                                                \"valid\": False,\n","                                                \"plot_LC\": True,\n","                                                \"checkpoint\": \"\",\n","                                                \"plot\": False,\n","                                                \"visualize\": False,\n","                                                \"downsize_input\": False,\n","                                                \"batch_size\":64,\n","                                                \"test_batch_size\":20,\n","                                                \"learning_rate\":0.008,\n","                                                \"weight_decay\":0.005,\n","                                                \"epochs\":300,\n","                                                \"ntrain\":ntrain,\n","                                                \"nvalid\":nvalid,\n","}\n","args.update(args_dict)\n","w_mse=1\n","w_mass=0.02\n","w_NSx=0.01\n","w_NSy=0.01\n","i=0\n","model=train_with_cross_validation(args, i, w_mse, w_mass, w_NSx, w_NSy, num_folds=10)"],"metadata":{"id":"a_A6J2U4UdWP"},"id":"a_A6J2U4UdWP","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6f1f1b5f","metadata":{"id":"6f1f1b5f"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"colab":{"provenance":[{"file_id":"1_Aq_JWPopSqPcjRrchTXdzkGYNLT-0b2","timestamp":1729954519822}]}},"nbformat":4,"nbformat_minor":5}